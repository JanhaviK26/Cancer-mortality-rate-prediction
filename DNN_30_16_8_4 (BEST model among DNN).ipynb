{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLFTc4PWFIm_",
        "outputId": "60935f67-e493-4e9b-b33c-94c0c7a7a0b6"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "JGB_UBlTGJDk"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the csv file that contains all the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/cancer_reg.csv', encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "PkyNrW4iF6gP"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# column names are lower cased to make them easy to write and read\n",
        "data.rename(columns=lambda x: str.lower(x), inplace=True)\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkuDyqP6F6cp",
        "outputId": "6158c6a5-45dc-46a3-a6c5-9a4f9b867c04"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3047 entries, 0 to 3046\n",
            "Data columns (total 34 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   avganncount              3047 non-null   float64\n",
            " 1   avgdeathsperyear         3047 non-null   int64  \n",
            " 2   target_deathrate         3047 non-null   float64\n",
            " 3   incidencerate            3047 non-null   float64\n",
            " 4   medincome                3047 non-null   int64  \n",
            " 5   popest2015               3047 non-null   int64  \n",
            " 6   povertypercent           3047 non-null   float64\n",
            " 7   studypercap              3047 non-null   float64\n",
            " 8   binnedinc                3047 non-null   object \n",
            " 9   medianage                3047 non-null   float64\n",
            " 10  medianagemale            3047 non-null   float64\n",
            " 11  medianagefemale          3047 non-null   float64\n",
            " 12  geography                3047 non-null   object \n",
            " 13  avghouseholdsize         3047 non-null   float64\n",
            " 14  percentmarried           3047 non-null   float64\n",
            " 15  pctnohs18_24             3047 non-null   float64\n",
            " 16  pcths18_24               3047 non-null   float64\n",
            " 17  pctsomecol18_24          762 non-null    float64\n",
            " 18  pctbachdeg18_24          3047 non-null   float64\n",
            " 19  pcths25_over             3047 non-null   float64\n",
            " 20  pctbachdeg25_over        3047 non-null   float64\n",
            " 21  pctemployed16_over       2895 non-null   float64\n",
            " 22  pctunemployed16_over     3047 non-null   float64\n",
            " 23  pctprivatecoverage       3047 non-null   float64\n",
            " 24  pctprivatecoveragealone  2438 non-null   float64\n",
            " 25  pctempprivcoverage       3047 non-null   float64\n",
            " 26  pctpubliccoverage        3047 non-null   float64\n",
            " 27  pctpubliccoveragealone   3047 non-null   float64\n",
            " 28  pctwhite                 3047 non-null   float64\n",
            " 29  pctblack                 3047 non-null   float64\n",
            " 30  pctasian                 3047 non-null   float64\n",
            " 31  pctotherrace             3047 non-null   float64\n",
            " 32  pctmarriedhouseholds     3047 non-null   float64\n",
            " 33  birthrate                3047 non-null   float64\n",
            "dtypes: float64(29), int64(3), object(2)\n",
            "memory usage: 809.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here, we drop features geograpghy abd binnedinc because they contain string values and we drop soe other features that contain Nan values\n",
        "df=data.drop(['geography', 'pctsomecol18_24','pctprivatecoveragealone','pctemployed16_over','binnedinc'], axis=1)"
      ],
      "metadata": {
        "id": "tRzt5Ls6F6ax"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr(method = 'pearson')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BW2o8TOlK_CV",
        "outputId": "24bf9e5d-be19-4e2b-a18a-bd6cf2597b3d"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        avganncount  avgdeathsperyear  target_deathrate  \\\n",
              "avganncount                1.000000          0.939408         -0.143532   \n",
              "avgdeathsperyear           0.939408          1.000000         -0.090715   \n",
              "target_deathrate          -0.143532         -0.090715          1.000000   \n",
              "incidencerate              0.073553          0.062690          0.449432   \n",
              "medincome                  0.269145          0.223207         -0.428615   \n",
              "popest2015                 0.926894          0.977634         -0.120073   \n",
              "povertypercent            -0.135694         -0.066918          0.429389   \n",
              "studypercap                0.082071          0.063488         -0.022285   \n",
              "medianage                 -0.024098         -0.024599          0.004375   \n",
              "medianagemale             -0.124969         -0.148487         -0.021929   \n",
              "medianagefemale           -0.122844         -0.144069          0.012048   \n",
              "avghouseholdsize           0.064788          0.086161         -0.036905   \n",
              "percentmarried            -0.106108         -0.181029         -0.266820   \n",
              "pctnohs18_24              -0.143327         -0.136794          0.088463   \n",
              "pcths18_24                -0.182054         -0.151418          0.261976   \n",
              "pctbachdeg18_24            0.284176          0.259761         -0.287817   \n",
              "pcths25_over              -0.311375         -0.295929          0.404589   \n",
              "pctbachdeg25_over          0.321021          0.293210         -0.485477   \n",
              "pctunemployed16_over      -0.009016          0.069701          0.378412   \n",
              "pctprivatecoverage         0.132244          0.056183         -0.386066   \n",
              "pctempprivcoverage         0.202349          0.160124         -0.267399   \n",
              "pctpubliccoverage         -0.173548         -0.131687          0.404572   \n",
              "pctpubliccoveragealone    -0.093699         -0.027338          0.449358   \n",
              "pctwhite                  -0.136501         -0.187159         -0.177400   \n",
              "pctblack                   0.031376          0.084607          0.257024   \n",
              "pctasian                   0.435071          0.443074         -0.186331   \n",
              "pctotherrace               0.209184          0.215149         -0.189894   \n",
              "pctmarriedhouseholds      -0.106221         -0.160266         -0.293325   \n",
              "birthrate                 -0.034508         -0.074420         -0.087407   \n",
              "\n",
              "                        incidencerate  medincome  popest2015  povertypercent  \\\n",
              "avganncount                  0.073553   0.269145    0.926894       -0.135694   \n",
              "avgdeathsperyear             0.062690   0.223207    0.977634       -0.066918   \n",
              "target_deathrate             0.449432  -0.428615   -0.120073        0.429389   \n",
              "incidencerate                1.000000  -0.001036    0.026912        0.009046   \n",
              "medincome                   -0.001036   1.000000    0.235523       -0.788965   \n",
              "popest2015                   0.026912   0.235523    1.000000       -0.065299   \n",
              "povertypercent               0.009046  -0.788965   -0.065299        1.000000   \n",
              "studypercap                  0.077283   0.044003    0.055722       -0.055652   \n",
              "medianage                    0.018089  -0.013288   -0.025219       -0.029280   \n",
              "medianagemale               -0.014733  -0.091663   -0.176608       -0.214001   \n",
              "medianagefemale             -0.009106  -0.153278   -0.177932       -0.148164   \n",
              "avghouseholdsize            -0.118400   0.112065    0.109940        0.074308   \n",
              "percentmarried              -0.119524   0.355123   -0.160463       -0.642857   \n",
              "pctnohs18_24                -0.170762  -0.289383   -0.126582        0.288106   \n",
              "pcths18_24                   0.022644  -0.190006   -0.151821        0.094211   \n",
              "pctbachdeg18_24              0.046835   0.492810    0.248375       -0.387122   \n",
              "pcths25_over                 0.121725  -0.471348   -0.311849        0.194361   \n",
              "pctbachdeg25_over           -0.038177   0.704928    0.297463       -0.531600   \n",
              "pctunemployed16_over         0.099979  -0.453108    0.050768        0.655148   \n",
              "pctprivatecoverage           0.105174   0.724175    0.052677       -0.822534   \n",
              "pctempprivcoverage           0.149825   0.747294    0.158650       -0.683100   \n",
              "pctpubliccoverage            0.046109  -0.754822   -0.160066        0.651162   \n",
              "pctpubliccoveragealone       0.040812  -0.719756   -0.041469        0.798642   \n",
              "pctwhite                    -0.014510   0.167225   -0.190095       -0.509433   \n",
              "pctblack                     0.113489  -0.270232    0.073044        0.511530   \n",
              "pctasian                    -0.008123   0.425844    0.464168       -0.157289   \n",
              "pctotherrace                -0.208748   0.083635    0.241468        0.047096   \n",
              "pctmarriedhouseholds        -0.152176   0.446083   -0.127979       -0.604953   \n",
              "birthrate                   -0.118181  -0.010195   -0.057740       -0.012283   \n",
              "\n",
              "                        studypercap  medianage  medianagemale  ...  \\\n",
              "avganncount                0.082071  -0.024098      -0.124969  ...   \n",
              "avgdeathsperyear           0.063488  -0.024599      -0.148487  ...   \n",
              "target_deathrate          -0.022285   0.004375      -0.021929  ...   \n",
              "incidencerate              0.077283   0.018089      -0.014733  ...   \n",
              "medincome                  0.044003  -0.013288      -0.091663  ...   \n",
              "popest2015                 0.055722  -0.025219      -0.176608  ...   \n",
              "povertypercent            -0.055652  -0.029280      -0.214001  ...   \n",
              "studypercap                1.000000  -0.026030      -0.036647  ...   \n",
              "medianage                 -0.026030   1.000000       0.129119  ...   \n",
              "medianagemale             -0.036647   0.129119       1.000000  ...   \n",
              "medianagefemale           -0.030577   0.124678       0.933696  ...   \n",
              "avghouseholdsize          -0.004071  -0.031944      -0.343189  ...   \n",
              "percentmarried            -0.038143   0.046372       0.449986  ...   \n",
              "pctnohs18_24              -0.090387   0.006178       0.100486  ...   \n",
              "pcths18_24                -0.057035   0.050574       0.241310  ...   \n",
              "pctbachdeg18_24            0.063819  -0.016909      -0.034135  ...   \n",
              "pcths25_over              -0.085128   0.036587       0.318277  ...   \n",
              "pctbachdeg25_over          0.108594  -0.020352      -0.131599  ...   \n",
              "pctunemployed16_over      -0.031957   0.018590      -0.142737  ...   \n",
              "pctprivatecoverage         0.092545   0.004665       0.082232  ...   \n",
              "pctempprivcoverage         0.100063  -0.036926      -0.208664  ...   \n",
              "pctpubliccoverage         -0.051497   0.049060       0.398967  ...   \n",
              "pctpubliccoveragealone    -0.055512  -0.003298       0.002479  ...   \n",
              "pctwhite                   0.023291   0.035009       0.398044  ...   \n",
              "pctblack                  -0.019761  -0.017173      -0.242748  ...   \n",
              "pctasian                   0.062543  -0.038424      -0.238322  ...   \n",
              "pctotherrace              -0.015247  -0.030277      -0.266655  ...   \n",
              "pctmarriedhouseholds      -0.051736   0.014504       0.222278  ...   \n",
              "birthrate                  0.010676  -0.008276      -0.104105  ...   \n",
              "\n",
              "                        pctprivatecoverage  pctempprivcoverage  \\\n",
              "avganncount                       0.132244            0.202349   \n",
              "avgdeathsperyear                  0.056183            0.160124   \n",
              "target_deathrate                 -0.386066           -0.267399   \n",
              "incidencerate                     0.105174            0.149825   \n",
              "medincome                         0.724175            0.747294   \n",
              "popest2015                        0.052677            0.158650   \n",
              "povertypercent                   -0.822534           -0.683100   \n",
              "studypercap                       0.092545            0.100063   \n",
              "medianage                         0.004665           -0.036926   \n",
              "medianagemale                     0.082232           -0.208664   \n",
              "medianagefemale                   0.046909           -0.252221   \n",
              "avghouseholdsize                 -0.144391            0.011111   \n",
              "percentmarried                    0.449452            0.232899   \n",
              "pctnohs18_24                     -0.454751           -0.429994   \n",
              "pcths18_24                       -0.253851           -0.244494   \n",
              "pctbachdeg18_24                   0.487742            0.450996   \n",
              "pcths25_over                     -0.221935           -0.222803   \n",
              "pctbachdeg25_over                 0.603248            0.539084   \n",
              "pctunemployed16_over             -0.634317           -0.474745   \n",
              "pctprivatecoverage                1.000000            0.827459   \n",
              "pctempprivcoverage                0.827459            1.000000   \n",
              "pctpubliccoverage                -0.720012           -0.778315   \n",
              "pctpubliccoveragealone           -0.886234           -0.728823   \n",
              "pctwhite                          0.429031            0.269815   \n",
              "pctblack                         -0.345172           -0.237388   \n",
              "pctasian                          0.189332            0.282484   \n",
              "pctotherrace                     -0.176300           -0.064226   \n",
              "pctmarriedhouseholds              0.434640            0.322569   \n",
              "birthrate                        -0.040437           -0.093878   \n",
              "\n",
              "                        pctpubliccoverage  pctpubliccoveragealone  pctwhite  \\\n",
              "avganncount                     -0.173548               -0.093699 -0.136501   \n",
              "avgdeathsperyear                -0.131687               -0.027338 -0.187159   \n",
              "target_deathrate                 0.404572                0.449358 -0.177400   \n",
              "incidencerate                    0.046109                0.040812 -0.014510   \n",
              "medincome                       -0.754822               -0.719756  0.167225   \n",
              "popest2015                      -0.160066               -0.041469 -0.190095   \n",
              "povertypercent                   0.651162                0.798642 -0.509433   \n",
              "studypercap                     -0.051497               -0.055512  0.023291   \n",
              "medianage                        0.049060               -0.003298  0.035009   \n",
              "medianagemale                    0.398967                0.002479  0.398044   \n",
              "medianagefemale                  0.455496                0.047659  0.339804   \n",
              "avghouseholdsize                -0.134812                0.061115 -0.188446   \n",
              "percentmarried                  -0.246972               -0.459990  0.677420   \n",
              "pctnohs18_24                     0.318540                0.327270 -0.157282   \n",
              "pcths18_24                       0.278220                0.234124  0.045306   \n",
              "pctbachdeg18_24                 -0.422470               -0.421805  0.069133   \n",
              "pcths25_over                     0.427974                0.297143  0.188045   \n",
              "pctbachdeg25_over               -0.636095               -0.605760  0.048652   \n",
              "pctunemployed16_over             0.529821                0.655366 -0.501755   \n",
              "pctprivatecoverage              -0.720012               -0.886234  0.429031   \n",
              "pctempprivcoverage              -0.778315               -0.728823  0.269815   \n",
              "pctpubliccoverage                1.000000                0.865833 -0.133705   \n",
              "pctpubliccoveragealone           0.865833                1.000000 -0.361026   \n",
              "pctwhite                        -0.133705               -0.361026  1.000000   \n",
              "pctblack                         0.195597                0.330110 -0.828459   \n",
              "pctasian                        -0.305625               -0.181380 -0.265676   \n",
              "pctotherrace                    -0.078708                0.083755 -0.233692   \n",
              "pctmarriedhouseholds            -0.362171               -0.473994  0.596771   \n",
              "birthrate                       -0.030531               -0.004753 -0.008958   \n",
              "\n",
              "                        pctblack  pctasian  pctotherrace  \\\n",
              "avganncount             0.031376  0.435071      0.209184   \n",
              "avgdeathsperyear        0.084607  0.443074      0.215149   \n",
              "target_deathrate        0.257024 -0.186331     -0.189894   \n",
              "incidencerate           0.113489 -0.008123     -0.208748   \n",
              "medincome              -0.270232  0.425844      0.083635   \n",
              "popest2015              0.073044  0.464168      0.241468   \n",
              "povertypercent          0.511530 -0.157289      0.047096   \n",
              "studypercap            -0.019761  0.062543     -0.015247   \n",
              "medianage              -0.017173 -0.038424     -0.030277   \n",
              "medianagemale          -0.242748 -0.238322     -0.266655   \n",
              "medianagefemale        -0.156728 -0.258748     -0.274120   \n",
              "avghouseholdsize        0.030278  0.131535      0.229440   \n",
              "percentmarried         -0.622357 -0.148691     -0.104669   \n",
              "pctnohs18_24            0.116805 -0.217535      0.126256   \n",
              "pcths18_24             -0.024868 -0.199770     -0.060415   \n",
              "pctbachdeg18_24        -0.093614  0.345883      0.006547   \n",
              "pcths25_over           -0.024445 -0.436561     -0.285611   \n",
              "pctbachdeg25_over      -0.146409  0.437963      0.039075   \n",
              "pctunemployed16_over    0.469273 -0.022020      0.028463   \n",
              "pctprivatecoverage     -0.345172  0.189332     -0.176300   \n",
              "pctempprivcoverage     -0.237388  0.282484     -0.064226   \n",
              "pctpubliccoverage       0.195597 -0.305625     -0.078708   \n",
              "pctpubliccoveragealone  0.330110 -0.181380      0.083755   \n",
              "pctwhite               -0.828459 -0.265676     -0.233692   \n",
              "pctblack                1.000000  0.016583     -0.023001   \n",
              "pctasian                0.016583  1.000000      0.200781   \n",
              "pctotherrace           -0.023001  0.200781      1.000000   \n",
              "pctmarriedhouseholds   -0.573592 -0.086602     -0.027352   \n",
              "birthrate              -0.067805 -0.061947      0.059829   \n",
              "\n",
              "                        pctmarriedhouseholds  birthrate  \n",
              "avganncount                        -0.106221  -0.034508  \n",
              "avgdeathsperyear                   -0.160266  -0.074420  \n",
              "target_deathrate                   -0.293325  -0.087407  \n",
              "incidencerate                      -0.152176  -0.118181  \n",
              "medincome                           0.446083  -0.010195  \n",
              "popest2015                         -0.127979  -0.057740  \n",
              "povertypercent                     -0.604953  -0.012283  \n",
              "studypercap                        -0.051736   0.010676  \n",
              "medianage                           0.014504  -0.008276  \n",
              "medianagemale                       0.222278  -0.104105  \n",
              "medianagefemale                     0.161507  -0.098813  \n",
              "avghouseholdsize                    0.091450   0.075918  \n",
              "percentmarried                      0.870261   0.141404  \n",
              "pctnohs18_24                        0.005340   0.125895  \n",
              "pcths18_24                          0.120040   0.058227  \n",
              "pctbachdeg18_24                    -0.000104  -0.125073  \n",
              "pcths25_over                        0.062176   0.016600  \n",
              "pctbachdeg25_over                   0.098134  -0.087940  \n",
              "pctunemployed16_over               -0.469609  -0.067906  \n",
              "pctprivatecoverage                  0.434640  -0.040437  \n",
              "pctempprivcoverage                  0.322569  -0.093878  \n",
              "pctpubliccoverage                  -0.362171  -0.030531  \n",
              "pctpubliccoveragealone             -0.473994  -0.004753  \n",
              "pctwhite                            0.596771  -0.008958  \n",
              "pctblack                           -0.573592  -0.067805  \n",
              "pctasian                           -0.086602  -0.061947  \n",
              "pctotherrace                       -0.027352   0.059829  \n",
              "pctmarriedhouseholds                1.000000   0.102263  \n",
              "birthrate                           0.102263   1.000000  \n",
              "\n",
              "[29 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5334e012-f6b5-4166-84b8-fbaec55a6113\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avganncount</th>\n",
              "      <th>avgdeathsperyear</th>\n",
              "      <th>target_deathrate</th>\n",
              "      <th>incidencerate</th>\n",
              "      <th>medincome</th>\n",
              "      <th>popest2015</th>\n",
              "      <th>povertypercent</th>\n",
              "      <th>studypercap</th>\n",
              "      <th>medianage</th>\n",
              "      <th>medianagemale</th>\n",
              "      <th>...</th>\n",
              "      <th>pctprivatecoverage</th>\n",
              "      <th>pctempprivcoverage</th>\n",
              "      <th>pctpubliccoverage</th>\n",
              "      <th>pctpubliccoveragealone</th>\n",
              "      <th>pctwhite</th>\n",
              "      <th>pctblack</th>\n",
              "      <th>pctasian</th>\n",
              "      <th>pctotherrace</th>\n",
              "      <th>pctmarriedhouseholds</th>\n",
              "      <th>birthrate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>avganncount</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.939408</td>\n",
              "      <td>-0.143532</td>\n",
              "      <td>0.073553</td>\n",
              "      <td>0.269145</td>\n",
              "      <td>0.926894</td>\n",
              "      <td>-0.135694</td>\n",
              "      <td>0.082071</td>\n",
              "      <td>-0.024098</td>\n",
              "      <td>-0.124969</td>\n",
              "      <td>...</td>\n",
              "      <td>0.132244</td>\n",
              "      <td>0.202349</td>\n",
              "      <td>-0.173548</td>\n",
              "      <td>-0.093699</td>\n",
              "      <td>-0.136501</td>\n",
              "      <td>0.031376</td>\n",
              "      <td>0.435071</td>\n",
              "      <td>0.209184</td>\n",
              "      <td>-0.106221</td>\n",
              "      <td>-0.034508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avgdeathsperyear</th>\n",
              "      <td>0.939408</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.090715</td>\n",
              "      <td>0.062690</td>\n",
              "      <td>0.223207</td>\n",
              "      <td>0.977634</td>\n",
              "      <td>-0.066918</td>\n",
              "      <td>0.063488</td>\n",
              "      <td>-0.024599</td>\n",
              "      <td>-0.148487</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056183</td>\n",
              "      <td>0.160124</td>\n",
              "      <td>-0.131687</td>\n",
              "      <td>-0.027338</td>\n",
              "      <td>-0.187159</td>\n",
              "      <td>0.084607</td>\n",
              "      <td>0.443074</td>\n",
              "      <td>0.215149</td>\n",
              "      <td>-0.160266</td>\n",
              "      <td>-0.074420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target_deathrate</th>\n",
              "      <td>-0.143532</td>\n",
              "      <td>-0.090715</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.449432</td>\n",
              "      <td>-0.428615</td>\n",
              "      <td>-0.120073</td>\n",
              "      <td>0.429389</td>\n",
              "      <td>-0.022285</td>\n",
              "      <td>0.004375</td>\n",
              "      <td>-0.021929</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.386066</td>\n",
              "      <td>-0.267399</td>\n",
              "      <td>0.404572</td>\n",
              "      <td>0.449358</td>\n",
              "      <td>-0.177400</td>\n",
              "      <td>0.257024</td>\n",
              "      <td>-0.186331</td>\n",
              "      <td>-0.189894</td>\n",
              "      <td>-0.293325</td>\n",
              "      <td>-0.087407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>incidencerate</th>\n",
              "      <td>0.073553</td>\n",
              "      <td>0.062690</td>\n",
              "      <td>0.449432</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.001036</td>\n",
              "      <td>0.026912</td>\n",
              "      <td>0.009046</td>\n",
              "      <td>0.077283</td>\n",
              "      <td>0.018089</td>\n",
              "      <td>-0.014733</td>\n",
              "      <td>...</td>\n",
              "      <td>0.105174</td>\n",
              "      <td>0.149825</td>\n",
              "      <td>0.046109</td>\n",
              "      <td>0.040812</td>\n",
              "      <td>-0.014510</td>\n",
              "      <td>0.113489</td>\n",
              "      <td>-0.008123</td>\n",
              "      <td>-0.208748</td>\n",
              "      <td>-0.152176</td>\n",
              "      <td>-0.118181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>medincome</th>\n",
              "      <td>0.269145</td>\n",
              "      <td>0.223207</td>\n",
              "      <td>-0.428615</td>\n",
              "      <td>-0.001036</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.235523</td>\n",
              "      <td>-0.788965</td>\n",
              "      <td>0.044003</td>\n",
              "      <td>-0.013288</td>\n",
              "      <td>-0.091663</td>\n",
              "      <td>...</td>\n",
              "      <td>0.724175</td>\n",
              "      <td>0.747294</td>\n",
              "      <td>-0.754822</td>\n",
              "      <td>-0.719756</td>\n",
              "      <td>0.167225</td>\n",
              "      <td>-0.270232</td>\n",
              "      <td>0.425844</td>\n",
              "      <td>0.083635</td>\n",
              "      <td>0.446083</td>\n",
              "      <td>-0.010195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>popest2015</th>\n",
              "      <td>0.926894</td>\n",
              "      <td>0.977634</td>\n",
              "      <td>-0.120073</td>\n",
              "      <td>0.026912</td>\n",
              "      <td>0.235523</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.065299</td>\n",
              "      <td>0.055722</td>\n",
              "      <td>-0.025219</td>\n",
              "      <td>-0.176608</td>\n",
              "      <td>...</td>\n",
              "      <td>0.052677</td>\n",
              "      <td>0.158650</td>\n",
              "      <td>-0.160066</td>\n",
              "      <td>-0.041469</td>\n",
              "      <td>-0.190095</td>\n",
              "      <td>0.073044</td>\n",
              "      <td>0.464168</td>\n",
              "      <td>0.241468</td>\n",
              "      <td>-0.127979</td>\n",
              "      <td>-0.057740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>povertypercent</th>\n",
              "      <td>-0.135694</td>\n",
              "      <td>-0.066918</td>\n",
              "      <td>0.429389</td>\n",
              "      <td>0.009046</td>\n",
              "      <td>-0.788965</td>\n",
              "      <td>-0.065299</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.055652</td>\n",
              "      <td>-0.029280</td>\n",
              "      <td>-0.214001</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.822534</td>\n",
              "      <td>-0.683100</td>\n",
              "      <td>0.651162</td>\n",
              "      <td>0.798642</td>\n",
              "      <td>-0.509433</td>\n",
              "      <td>0.511530</td>\n",
              "      <td>-0.157289</td>\n",
              "      <td>0.047096</td>\n",
              "      <td>-0.604953</td>\n",
              "      <td>-0.012283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>studypercap</th>\n",
              "      <td>0.082071</td>\n",
              "      <td>0.063488</td>\n",
              "      <td>-0.022285</td>\n",
              "      <td>0.077283</td>\n",
              "      <td>0.044003</td>\n",
              "      <td>0.055722</td>\n",
              "      <td>-0.055652</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.026030</td>\n",
              "      <td>-0.036647</td>\n",
              "      <td>...</td>\n",
              "      <td>0.092545</td>\n",
              "      <td>0.100063</td>\n",
              "      <td>-0.051497</td>\n",
              "      <td>-0.055512</td>\n",
              "      <td>0.023291</td>\n",
              "      <td>-0.019761</td>\n",
              "      <td>0.062543</td>\n",
              "      <td>-0.015247</td>\n",
              "      <td>-0.051736</td>\n",
              "      <td>0.010676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>medianage</th>\n",
              "      <td>-0.024098</td>\n",
              "      <td>-0.024599</td>\n",
              "      <td>0.004375</td>\n",
              "      <td>0.018089</td>\n",
              "      <td>-0.013288</td>\n",
              "      <td>-0.025219</td>\n",
              "      <td>-0.029280</td>\n",
              "      <td>-0.026030</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.129119</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004665</td>\n",
              "      <td>-0.036926</td>\n",
              "      <td>0.049060</td>\n",
              "      <td>-0.003298</td>\n",
              "      <td>0.035009</td>\n",
              "      <td>-0.017173</td>\n",
              "      <td>-0.038424</td>\n",
              "      <td>-0.030277</td>\n",
              "      <td>0.014504</td>\n",
              "      <td>-0.008276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>medianagemale</th>\n",
              "      <td>-0.124969</td>\n",
              "      <td>-0.148487</td>\n",
              "      <td>-0.021929</td>\n",
              "      <td>-0.014733</td>\n",
              "      <td>-0.091663</td>\n",
              "      <td>-0.176608</td>\n",
              "      <td>-0.214001</td>\n",
              "      <td>-0.036647</td>\n",
              "      <td>0.129119</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.082232</td>\n",
              "      <td>-0.208664</td>\n",
              "      <td>0.398967</td>\n",
              "      <td>0.002479</td>\n",
              "      <td>0.398044</td>\n",
              "      <td>-0.242748</td>\n",
              "      <td>-0.238322</td>\n",
              "      <td>-0.266655</td>\n",
              "      <td>0.222278</td>\n",
              "      <td>-0.104105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>medianagefemale</th>\n",
              "      <td>-0.122844</td>\n",
              "      <td>-0.144069</td>\n",
              "      <td>0.012048</td>\n",
              "      <td>-0.009106</td>\n",
              "      <td>-0.153278</td>\n",
              "      <td>-0.177932</td>\n",
              "      <td>-0.148164</td>\n",
              "      <td>-0.030577</td>\n",
              "      <td>0.124678</td>\n",
              "      <td>0.933696</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046909</td>\n",
              "      <td>-0.252221</td>\n",
              "      <td>0.455496</td>\n",
              "      <td>0.047659</td>\n",
              "      <td>0.339804</td>\n",
              "      <td>-0.156728</td>\n",
              "      <td>-0.258748</td>\n",
              "      <td>-0.274120</td>\n",
              "      <td>0.161507</td>\n",
              "      <td>-0.098813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avghouseholdsize</th>\n",
              "      <td>0.064788</td>\n",
              "      <td>0.086161</td>\n",
              "      <td>-0.036905</td>\n",
              "      <td>-0.118400</td>\n",
              "      <td>0.112065</td>\n",
              "      <td>0.109940</td>\n",
              "      <td>0.074308</td>\n",
              "      <td>-0.004071</td>\n",
              "      <td>-0.031944</td>\n",
              "      <td>-0.343189</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.144391</td>\n",
              "      <td>0.011111</td>\n",
              "      <td>-0.134812</td>\n",
              "      <td>0.061115</td>\n",
              "      <td>-0.188446</td>\n",
              "      <td>0.030278</td>\n",
              "      <td>0.131535</td>\n",
              "      <td>0.229440</td>\n",
              "      <td>0.091450</td>\n",
              "      <td>0.075918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percentmarried</th>\n",
              "      <td>-0.106108</td>\n",
              "      <td>-0.181029</td>\n",
              "      <td>-0.266820</td>\n",
              "      <td>-0.119524</td>\n",
              "      <td>0.355123</td>\n",
              "      <td>-0.160463</td>\n",
              "      <td>-0.642857</td>\n",
              "      <td>-0.038143</td>\n",
              "      <td>0.046372</td>\n",
              "      <td>0.449986</td>\n",
              "      <td>...</td>\n",
              "      <td>0.449452</td>\n",
              "      <td>0.232899</td>\n",
              "      <td>-0.246972</td>\n",
              "      <td>-0.459990</td>\n",
              "      <td>0.677420</td>\n",
              "      <td>-0.622357</td>\n",
              "      <td>-0.148691</td>\n",
              "      <td>-0.104669</td>\n",
              "      <td>0.870261</td>\n",
              "      <td>0.141404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctnohs18_24</th>\n",
              "      <td>-0.143327</td>\n",
              "      <td>-0.136794</td>\n",
              "      <td>0.088463</td>\n",
              "      <td>-0.170762</td>\n",
              "      <td>-0.289383</td>\n",
              "      <td>-0.126582</td>\n",
              "      <td>0.288106</td>\n",
              "      <td>-0.090387</td>\n",
              "      <td>0.006178</td>\n",
              "      <td>0.100486</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.454751</td>\n",
              "      <td>-0.429994</td>\n",
              "      <td>0.318540</td>\n",
              "      <td>0.327270</td>\n",
              "      <td>-0.157282</td>\n",
              "      <td>0.116805</td>\n",
              "      <td>-0.217535</td>\n",
              "      <td>0.126256</td>\n",
              "      <td>0.005340</td>\n",
              "      <td>0.125895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pcths18_24</th>\n",
              "      <td>-0.182054</td>\n",
              "      <td>-0.151418</td>\n",
              "      <td>0.261976</td>\n",
              "      <td>0.022644</td>\n",
              "      <td>-0.190006</td>\n",
              "      <td>-0.151821</td>\n",
              "      <td>0.094211</td>\n",
              "      <td>-0.057035</td>\n",
              "      <td>0.050574</td>\n",
              "      <td>0.241310</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.253851</td>\n",
              "      <td>-0.244494</td>\n",
              "      <td>0.278220</td>\n",
              "      <td>0.234124</td>\n",
              "      <td>0.045306</td>\n",
              "      <td>-0.024868</td>\n",
              "      <td>-0.199770</td>\n",
              "      <td>-0.060415</td>\n",
              "      <td>0.120040</td>\n",
              "      <td>0.058227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctbachdeg18_24</th>\n",
              "      <td>0.284176</td>\n",
              "      <td>0.259761</td>\n",
              "      <td>-0.287817</td>\n",
              "      <td>0.046835</td>\n",
              "      <td>0.492810</td>\n",
              "      <td>0.248375</td>\n",
              "      <td>-0.387122</td>\n",
              "      <td>0.063819</td>\n",
              "      <td>-0.016909</td>\n",
              "      <td>-0.034135</td>\n",
              "      <td>...</td>\n",
              "      <td>0.487742</td>\n",
              "      <td>0.450996</td>\n",
              "      <td>-0.422470</td>\n",
              "      <td>-0.421805</td>\n",
              "      <td>0.069133</td>\n",
              "      <td>-0.093614</td>\n",
              "      <td>0.345883</td>\n",
              "      <td>0.006547</td>\n",
              "      <td>-0.000104</td>\n",
              "      <td>-0.125073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pcths25_over</th>\n",
              "      <td>-0.311375</td>\n",
              "      <td>-0.295929</td>\n",
              "      <td>0.404589</td>\n",
              "      <td>0.121725</td>\n",
              "      <td>-0.471348</td>\n",
              "      <td>-0.311849</td>\n",
              "      <td>0.194361</td>\n",
              "      <td>-0.085128</td>\n",
              "      <td>0.036587</td>\n",
              "      <td>0.318277</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.221935</td>\n",
              "      <td>-0.222803</td>\n",
              "      <td>0.427974</td>\n",
              "      <td>0.297143</td>\n",
              "      <td>0.188045</td>\n",
              "      <td>-0.024445</td>\n",
              "      <td>-0.436561</td>\n",
              "      <td>-0.285611</td>\n",
              "      <td>0.062176</td>\n",
              "      <td>0.016600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctbachdeg25_over</th>\n",
              "      <td>0.321021</td>\n",
              "      <td>0.293210</td>\n",
              "      <td>-0.485477</td>\n",
              "      <td>-0.038177</td>\n",
              "      <td>0.704928</td>\n",
              "      <td>0.297463</td>\n",
              "      <td>-0.531600</td>\n",
              "      <td>0.108594</td>\n",
              "      <td>-0.020352</td>\n",
              "      <td>-0.131599</td>\n",
              "      <td>...</td>\n",
              "      <td>0.603248</td>\n",
              "      <td>0.539084</td>\n",
              "      <td>-0.636095</td>\n",
              "      <td>-0.605760</td>\n",
              "      <td>0.048652</td>\n",
              "      <td>-0.146409</td>\n",
              "      <td>0.437963</td>\n",
              "      <td>0.039075</td>\n",
              "      <td>0.098134</td>\n",
              "      <td>-0.087940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctunemployed16_over</th>\n",
              "      <td>-0.009016</td>\n",
              "      <td>0.069701</td>\n",
              "      <td>0.378412</td>\n",
              "      <td>0.099979</td>\n",
              "      <td>-0.453108</td>\n",
              "      <td>0.050768</td>\n",
              "      <td>0.655148</td>\n",
              "      <td>-0.031957</td>\n",
              "      <td>0.018590</td>\n",
              "      <td>-0.142737</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.634317</td>\n",
              "      <td>-0.474745</td>\n",
              "      <td>0.529821</td>\n",
              "      <td>0.655366</td>\n",
              "      <td>-0.501755</td>\n",
              "      <td>0.469273</td>\n",
              "      <td>-0.022020</td>\n",
              "      <td>0.028463</td>\n",
              "      <td>-0.469609</td>\n",
              "      <td>-0.067906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctprivatecoverage</th>\n",
              "      <td>0.132244</td>\n",
              "      <td>0.056183</td>\n",
              "      <td>-0.386066</td>\n",
              "      <td>0.105174</td>\n",
              "      <td>0.724175</td>\n",
              "      <td>0.052677</td>\n",
              "      <td>-0.822534</td>\n",
              "      <td>0.092545</td>\n",
              "      <td>0.004665</td>\n",
              "      <td>0.082232</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.827459</td>\n",
              "      <td>-0.720012</td>\n",
              "      <td>-0.886234</td>\n",
              "      <td>0.429031</td>\n",
              "      <td>-0.345172</td>\n",
              "      <td>0.189332</td>\n",
              "      <td>-0.176300</td>\n",
              "      <td>0.434640</td>\n",
              "      <td>-0.040437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctempprivcoverage</th>\n",
              "      <td>0.202349</td>\n",
              "      <td>0.160124</td>\n",
              "      <td>-0.267399</td>\n",
              "      <td>0.149825</td>\n",
              "      <td>0.747294</td>\n",
              "      <td>0.158650</td>\n",
              "      <td>-0.683100</td>\n",
              "      <td>0.100063</td>\n",
              "      <td>-0.036926</td>\n",
              "      <td>-0.208664</td>\n",
              "      <td>...</td>\n",
              "      <td>0.827459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.778315</td>\n",
              "      <td>-0.728823</td>\n",
              "      <td>0.269815</td>\n",
              "      <td>-0.237388</td>\n",
              "      <td>0.282484</td>\n",
              "      <td>-0.064226</td>\n",
              "      <td>0.322569</td>\n",
              "      <td>-0.093878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctpubliccoverage</th>\n",
              "      <td>-0.173548</td>\n",
              "      <td>-0.131687</td>\n",
              "      <td>0.404572</td>\n",
              "      <td>0.046109</td>\n",
              "      <td>-0.754822</td>\n",
              "      <td>-0.160066</td>\n",
              "      <td>0.651162</td>\n",
              "      <td>-0.051497</td>\n",
              "      <td>0.049060</td>\n",
              "      <td>0.398967</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.720012</td>\n",
              "      <td>-0.778315</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.865833</td>\n",
              "      <td>-0.133705</td>\n",
              "      <td>0.195597</td>\n",
              "      <td>-0.305625</td>\n",
              "      <td>-0.078708</td>\n",
              "      <td>-0.362171</td>\n",
              "      <td>-0.030531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctpubliccoveragealone</th>\n",
              "      <td>-0.093699</td>\n",
              "      <td>-0.027338</td>\n",
              "      <td>0.449358</td>\n",
              "      <td>0.040812</td>\n",
              "      <td>-0.719756</td>\n",
              "      <td>-0.041469</td>\n",
              "      <td>0.798642</td>\n",
              "      <td>-0.055512</td>\n",
              "      <td>-0.003298</td>\n",
              "      <td>0.002479</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.886234</td>\n",
              "      <td>-0.728823</td>\n",
              "      <td>0.865833</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.361026</td>\n",
              "      <td>0.330110</td>\n",
              "      <td>-0.181380</td>\n",
              "      <td>0.083755</td>\n",
              "      <td>-0.473994</td>\n",
              "      <td>-0.004753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctwhite</th>\n",
              "      <td>-0.136501</td>\n",
              "      <td>-0.187159</td>\n",
              "      <td>-0.177400</td>\n",
              "      <td>-0.014510</td>\n",
              "      <td>0.167225</td>\n",
              "      <td>-0.190095</td>\n",
              "      <td>-0.509433</td>\n",
              "      <td>0.023291</td>\n",
              "      <td>0.035009</td>\n",
              "      <td>0.398044</td>\n",
              "      <td>...</td>\n",
              "      <td>0.429031</td>\n",
              "      <td>0.269815</td>\n",
              "      <td>-0.133705</td>\n",
              "      <td>-0.361026</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.828459</td>\n",
              "      <td>-0.265676</td>\n",
              "      <td>-0.233692</td>\n",
              "      <td>0.596771</td>\n",
              "      <td>-0.008958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctblack</th>\n",
              "      <td>0.031376</td>\n",
              "      <td>0.084607</td>\n",
              "      <td>0.257024</td>\n",
              "      <td>0.113489</td>\n",
              "      <td>-0.270232</td>\n",
              "      <td>0.073044</td>\n",
              "      <td>0.511530</td>\n",
              "      <td>-0.019761</td>\n",
              "      <td>-0.017173</td>\n",
              "      <td>-0.242748</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.345172</td>\n",
              "      <td>-0.237388</td>\n",
              "      <td>0.195597</td>\n",
              "      <td>0.330110</td>\n",
              "      <td>-0.828459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>-0.023001</td>\n",
              "      <td>-0.573592</td>\n",
              "      <td>-0.067805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctasian</th>\n",
              "      <td>0.435071</td>\n",
              "      <td>0.443074</td>\n",
              "      <td>-0.186331</td>\n",
              "      <td>-0.008123</td>\n",
              "      <td>0.425844</td>\n",
              "      <td>0.464168</td>\n",
              "      <td>-0.157289</td>\n",
              "      <td>0.062543</td>\n",
              "      <td>-0.038424</td>\n",
              "      <td>-0.238322</td>\n",
              "      <td>...</td>\n",
              "      <td>0.189332</td>\n",
              "      <td>0.282484</td>\n",
              "      <td>-0.305625</td>\n",
              "      <td>-0.181380</td>\n",
              "      <td>-0.265676</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200781</td>\n",
              "      <td>-0.086602</td>\n",
              "      <td>-0.061947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctotherrace</th>\n",
              "      <td>0.209184</td>\n",
              "      <td>0.215149</td>\n",
              "      <td>-0.189894</td>\n",
              "      <td>-0.208748</td>\n",
              "      <td>0.083635</td>\n",
              "      <td>0.241468</td>\n",
              "      <td>0.047096</td>\n",
              "      <td>-0.015247</td>\n",
              "      <td>-0.030277</td>\n",
              "      <td>-0.266655</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.176300</td>\n",
              "      <td>-0.064226</td>\n",
              "      <td>-0.078708</td>\n",
              "      <td>0.083755</td>\n",
              "      <td>-0.233692</td>\n",
              "      <td>-0.023001</td>\n",
              "      <td>0.200781</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.027352</td>\n",
              "      <td>0.059829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pctmarriedhouseholds</th>\n",
              "      <td>-0.106221</td>\n",
              "      <td>-0.160266</td>\n",
              "      <td>-0.293325</td>\n",
              "      <td>-0.152176</td>\n",
              "      <td>0.446083</td>\n",
              "      <td>-0.127979</td>\n",
              "      <td>-0.604953</td>\n",
              "      <td>-0.051736</td>\n",
              "      <td>0.014504</td>\n",
              "      <td>0.222278</td>\n",
              "      <td>...</td>\n",
              "      <td>0.434640</td>\n",
              "      <td>0.322569</td>\n",
              "      <td>-0.362171</td>\n",
              "      <td>-0.473994</td>\n",
              "      <td>0.596771</td>\n",
              "      <td>-0.573592</td>\n",
              "      <td>-0.086602</td>\n",
              "      <td>-0.027352</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.102263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>birthrate</th>\n",
              "      <td>-0.034508</td>\n",
              "      <td>-0.074420</td>\n",
              "      <td>-0.087407</td>\n",
              "      <td>-0.118181</td>\n",
              "      <td>-0.010195</td>\n",
              "      <td>-0.057740</td>\n",
              "      <td>-0.012283</td>\n",
              "      <td>0.010676</td>\n",
              "      <td>-0.008276</td>\n",
              "      <td>-0.104105</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.040437</td>\n",
              "      <td>-0.093878</td>\n",
              "      <td>-0.030531</td>\n",
              "      <td>-0.004753</td>\n",
              "      <td>-0.008958</td>\n",
              "      <td>-0.067805</td>\n",
              "      <td>-0.061947</td>\n",
              "      <td>0.059829</td>\n",
              "      <td>0.102263</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29 rows × 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5334e012-f6b5-4166-84b8-fbaec55a6113')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5334e012-f6b5-4166-84b8-fbaec55a6113 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5334e012-f6b5-4166-84b8-fbaec55a6113');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a30689db-ecca-45ac-aa00-513e7c7a579b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a30689db-ecca-45ac-aa00-513e7c7a579b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a30689db-ecca-45ac-aa00-513e7c7a579b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_all = df.drop(columns=['target_deathrate'],axis=1)  # Replace 'target_deathrate' with the target column name\n",
        "target = df['target_deathrate']\n"
      ],
      "metadata": {
        "id": "PhGZRmX_LOL5"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading input and outpur\n",
        "X=dataset[['incidencerate','pctpubliccoveragealone','povertypercent','pcths25_over','pctpubliccoverage', 'pctunemployed16_over', 'pcths18_24']]\n",
        "Y=dataset['target_deathrate']"
      ],
      "metadata": {
        "id": "xqxWs3yKF1DE"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "sWEMQItxFr89"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2, random_state=50)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.2, random_state=50)\n"
      ],
      "metadata": {
        "id": "a-uQTxeNFr5o"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8LxBMJAyFw96"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "T6JELDDGFIdP"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "e_JngmXKEU5V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "seed_value = 0\n",
        "\n",
        "# Set the random seeds for reproducibility\n",
        "\n",
        "np.random.seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QbAPMQvvekTQ"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code for printed date and time\n",
        "# Custom callback to add date and time at the beginning and end of each epoch\n",
        "import time\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class TimeHistory(Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_time_start = time.time()\n",
        "        self.start_time = datetime.now()  # Store the start time for each epoch\n",
        "        print(f\"Epoch {epoch + 1} started at {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        epoch_duration = time.time() - self.epoch_time_start\n",
        "        self.end_time = datetime.now()  # Store the end time for each epoch\n",
        "        print(f\"Epoch {epoch + 1} ended at {self.end_time.strftime('%Y-%m-%d %H:%M:%S')} and took {epoch_duration:.2f} seconds\")"
      ],
      "metadata": {
        "id": "8DGypD58a_u_"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = Sequential()\n",
        "test_model.add(Dense(30, input_dim=X_train.shape[1], activation='relu'))  # First hidden layer with 30 neurons\n",
        "test_model.add(Dense(16, activation='relu'))  # Second hidden layer with ReLU activation\n",
        "test_model.add(Dense(8, activation='relu'))  # Second hidden layer with ReLU activation\n",
        "test_model.add(Dense(4, activation='relu')) # adding fourth hidden layer with ReLU\n",
        "\n",
        "test_model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Compile the model with Adam optimizer\n",
        "test_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "time_callback = TimeHistory()\n",
        "\n",
        "# Train the model\n",
        "history=test_model.fit(X_train, Y_train, epochs=100, verbose=1,validation_split=0.2,callbacks=[time_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdASb0YbEy8t",
        "outputId": "d7c4d0e7-777c-4f6f-aef1-9bb124f3d64d"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 started at 2024-09-21 16:50:23\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32471.8457 Epoch 1 ended at 2024-09-21 16:50:25 and took 1.95 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 32617.8125 - val_loss: 32343.7285\n",
            "Epoch 2 started at 2024-09-21 16:50:25\n",
            "Epoch 2/100\n",
            "\u001b[1m46/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32269.8516Epoch 2 ended at 2024-09-21 16:50:25 and took 0.60 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 32287.5762 - val_loss: 31420.3047\n",
            "Epoch 3 started at 2024-09-21 16:50:25\n",
            "Epoch 3/100\n",
            "\u001b[1m41/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30940.5410Epoch 3 ended at 2024-09-21 16:50:26 and took 0.26 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30875.6445 - val_loss: 27827.3535\n",
            "Epoch 4 started at 2024-09-21 16:50:26\n",
            "Epoch 4/100\n",
            "\u001b[1m40/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26263.3496Epoch 4 ended at 2024-09-21 16:50:26 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 25859.9609 - val_loss: 17930.5195\n",
            "Epoch 5 started at 2024-09-21 16:50:26\n",
            "Epoch 5/100\n",
            "\u001b[1m41/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15038.4434Epoch 5 ended at 2024-09-21 16:50:26 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14502.4131 - val_loss: 6617.3154\n",
            "Epoch 6 started at 2024-09-21 16:50:26\n",
            "Epoch 6/100\n",
            "\u001b[1m39/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5620.5200Epoch 6 ended at 2024-09-21 16:50:26 and took 0.23 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5522.6943 - val_loss: 4399.4751\n",
            "Epoch 7 started at 2024-09-21 16:50:26\n",
            "Epoch 7/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4108.6660Epoch 7 ended at 2024-09-21 16:50:27 and took 0.24 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4045.8325 - val_loss: 3630.4897\n",
            "Epoch 8 started at 2024-09-21 16:50:27\n",
            "Epoch 8/100\n",
            "\u001b[1m41/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3338.9031Epoch 8 ended at 2024-09-21 16:50:27 and took 0.28 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3324.7410 - val_loss: 3059.1426\n",
            "Epoch 9 started at 2024-09-21 16:50:27\n",
            "Epoch 9/100\n",
            "\u001b[1m38/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2755.3787Epoch 9 ended at 2024-09-21 16:50:27 and took 0.35 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2754.2734 - val_loss: 2620.6956\n",
            "Epoch 10 started at 2024-09-21 16:50:27\n",
            "Epoch 10/100\n",
            "\u001b[1m39/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2308.2053Epoch 10 ended at 2024-09-21 16:50:28 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2317.1785 - val_loss: 2279.6250\n",
            "Epoch 11 started at 2024-09-21 16:50:28\n",
            "Epoch 11/100\n",
            "\u001b[1m36/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1949.5300Epoch 11 ended at 2024-09-21 16:50:28 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1972.1466 - val_loss: 2004.0654\n",
            "Epoch 12 started at 2024-09-21 16:50:28\n",
            "Epoch 12/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1691.9324Epoch 12 ended at 2024-09-21 16:50:28 and took 0.32 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1692.7888 - val_loss: 1782.4426\n",
            "Epoch 13 started at 2024-09-21 16:50:28\n",
            "Epoch 13/100\n",
            "\u001b[1m34/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1438.1226   Epoch 13 ended at 2024-09-21 16:50:29 and took 0.49 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1472.2886 - val_loss: 1600.6748\n",
            "Epoch 14 started at 2024-09-21 16:50:29\n",
            "Epoch 14/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1260.7843 Epoch 14 ended at 2024-09-21 16:50:29 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1294.9232 - val_loss: 1449.0072\n",
            "Epoch 15 started at 2024-09-21 16:50:29\n",
            "Epoch 15/100\n",
            "\u001b[1m34/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1117.4982 Epoch 15 ended at 2024-09-21 16:50:29 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1150.4478 - val_loss: 1326.0363\n",
            "Epoch 16 started at 2024-09-21 16:50:29\n",
            "Epoch 16/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1001.7365Epoch 16 ended at 2024-09-21 16:50:29 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1033.3213 - val_loss: 1222.5651\n",
            "Epoch 17 started at 2024-09-21 16:50:29\n",
            "Epoch 17/100\n",
            "\u001b[1m29/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 906.9946  Epoch 17 ended at 2024-09-21 16:50:30 and took 0.32 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 935.9598 - val_loss: 1134.0039\n",
            "Epoch 18 started at 2024-09-21 16:50:30\n",
            "Epoch 18/100\n",
            "\u001b[1m34/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 828.9946  Epoch 18 ended at 2024-09-21 16:50:30 and took 0.28 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 855.2902 - val_loss: 1059.9097\n",
            "Epoch 19 started at 2024-09-21 16:50:30\n",
            "Epoch 19/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 763.9653  Epoch 19 ended at 2024-09-21 16:50:30 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 788.1337 - val_loss: 995.0873\n",
            "Epoch 20 started at 2024-09-21 16:50:30\n",
            "Epoch 20/100\n",
            "\u001b[1m33/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 706.6144  Epoch 20 ended at 2024-09-21 16:50:31 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 728.5457 - val_loss: 941.6342\n",
            "Epoch 21 started at 2024-09-21 16:50:31\n",
            "Epoch 21/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 659.8401  Epoch 21 ended at 2024-09-21 16:50:31 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 678.8721 - val_loss: 894.3442\n",
            "Epoch 22 started at 2024-09-21 16:50:31\n",
            "Epoch 22/100\n",
            "\u001b[1m35/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 622.1103 Epoch 22 ended at 2024-09-21 16:50:31 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 637.6123 - val_loss: 853.1775\n",
            "Epoch 23 started at 2024-09-21 16:50:31\n",
            "Epoch 23/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 587.4844  Epoch 23 ended at 2024-09-21 16:50:31 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 602.2267 - val_loss: 818.2530\n",
            "Epoch 24 started at 2024-09-21 16:50:31\n",
            "Epoch 24/100\n",
            "\u001b[1m30/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 560.2572  Epoch 24 ended at 2024-09-21 16:50:32 and took 0.31 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 573.0742 - val_loss: 788.0066\n",
            "Epoch 25 started at 2024-09-21 16:50:32\n",
            "Epoch 25/100\n",
            "\u001b[1m26/49\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 537.5027  Epoch 25 ended at 2024-09-21 16:50:32 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 547.8066 - val_loss: 761.9534\n",
            "Epoch 26 started at 2024-09-21 16:50:32\n",
            "Epoch 26/100\n",
            "\u001b[1m26/49\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 517.5367 Epoch 26 ended at 2024-09-21 16:50:32 and took 0.17 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 526.5248 - val_loss: 739.3617\n",
            "Epoch 27 started at 2024-09-21 16:50:32\n",
            "Epoch 27/100\n",
            "\u001b[1m29/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 499.5977  Epoch 27 ended at 2024-09-21 16:50:32 and took 0.28 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 508.2223 - val_loss: 719.1678\n",
            "Epoch 28 started at 2024-09-21 16:50:32\n",
            "Epoch 28/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 484.8881  Epoch 28 ended at 2024-09-21 16:50:33 and took 0.34 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 492.5547 - val_loss: 702.7077\n",
            "Epoch 29 started at 2024-09-21 16:50:33\n",
            "Epoch 29/100\n",
            "\u001b[1m34/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 472.9505  Epoch 29 ended at 2024-09-21 16:50:33 and took 0.25 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 479.5549 - val_loss: 687.9499\n",
            "Epoch 30 started at 2024-09-21 16:50:33\n",
            "Epoch 30/100\n",
            "\u001b[1m24/49\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 463.3637 Epoch 30 ended at 2024-09-21 16:50:33 and took 0.17 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 468.1188 - val_loss: 676.0067\n",
            "Epoch 31 started at 2024-09-21 16:50:33\n",
            "Epoch 31/100\n",
            "\u001b[1m35/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453.4294  Epoch 31 ended at 2024-09-21 16:50:33 and took 0.28 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457.9806 - val_loss: 664.9586\n",
            "Epoch 32 started at 2024-09-21 16:50:33\n",
            "Epoch 32/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444.7929 Epoch 32 ended at 2024-09-21 16:50:34 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 449.1690 - val_loss: 654.8422\n",
            "Epoch 33 started at 2024-09-21 16:50:34\n",
            "Epoch 33/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 437.6713  Epoch 33 ended at 2024-09-21 16:50:34 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 441.5388 - val_loss: 646.6288\n",
            "Epoch 34 started at 2024-09-21 16:50:34\n",
            "Epoch 34/100\n",
            "\u001b[1m30/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431.3179  Epoch 34 ended at 2024-09-21 16:50:34 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 434.8162 - val_loss: 638.8360\n",
            "Epoch 35 started at 2024-09-21 16:50:34\n",
            "Epoch 35/100\n",
            "\u001b[1m30/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 425.9661  Epoch 35 ended at 2024-09-21 16:50:34 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 429.1517 - val_loss: 632.6201\n",
            "Epoch 36 started at 2024-09-21 16:50:34\n",
            "Epoch 36/100\n",
            "\u001b[1m28/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 421.1594 Epoch 36 ended at 2024-09-21 16:50:35 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 424.1628 - val_loss: 626.8607\n",
            "Epoch 37 started at 2024-09-21 16:50:35\n",
            "Epoch 37/100\n",
            "\u001b[1m21/49\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 418.0494 Epoch 37 ended at 2024-09-21 16:50:35 and took 0.17 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 419.7953 - val_loss: 620.4155\n",
            "Epoch 38 started at 2024-09-21 16:50:35\n",
            "Epoch 38/100\n",
            "\u001b[1m25/49\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413.7759  Epoch 38 ended at 2024-09-21 16:50:35 and took 0.31 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 416.0937 - val_loss: 616.8384\n",
            "Epoch 39 started at 2024-09-21 16:50:35\n",
            "Epoch 39/100\n",
            "\u001b[1m33/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 410.3160  Epoch 39 ended at 2024-09-21 16:50:35 and took 0.28 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 412.7953 - val_loss: 613.0773\n",
            "Epoch 40 started at 2024-09-21 16:50:35\n",
            "Epoch 40/100\n",
            "\u001b[1m35/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 408.1916 Epoch 40 ended at 2024-09-21 16:50:36 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409.9650 - val_loss: 609.1876\n",
            "Epoch 41 started at 2024-09-21 16:50:36\n",
            "Epoch 41/100\n",
            "\u001b[1m33/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 405.1487 Epoch 41 ended at 2024-09-21 16:50:36 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 407.3642 - val_loss: 606.1306\n",
            "Epoch 42 started at 2024-09-21 16:50:36\n",
            "Epoch 42/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403.3120 Epoch 42 ended at 2024-09-21 16:50:36 and took 0.17 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 405.3241 - val_loss: 603.3849\n",
            "Epoch 43 started at 2024-09-21 16:50:36\n",
            "Epoch 43/100\n",
            "\u001b[1m33/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 401.4445 Epoch 43 ended at 2024-09-21 16:50:36 and took 0.16 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 403.4279 - val_loss: 600.8395\n",
            "Epoch 44 started at 2024-09-21 16:50:36\n",
            "Epoch 44/100\n",
            "\u001b[1m29/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 399.5787  Epoch 44 ended at 2024-09-21 16:50:36 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 401.7384 - val_loss: 596.9646\n",
            "Epoch 45 started at 2024-09-21 16:50:36\n",
            "Epoch 45/100\n",
            "\u001b[1m30/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.9949 Epoch 45 ended at 2024-09-21 16:50:37 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 399.9554 - val_loss: 594.1584\n",
            "Epoch 46 started at 2024-09-21 16:50:37\n",
            "Epoch 46/100\n",
            "\u001b[1m28/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 396.4212  Epoch 46 ended at 2024-09-21 16:50:37 and took 0.32 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 398.5305 - val_loss: 591.7335\n",
            "Epoch 47 started at 2024-09-21 16:50:37\n",
            "Epoch 47/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 395.6746 Epoch 47 ended at 2024-09-21 16:50:37 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 397.1093 - val_loss: 588.8254\n",
            "Epoch 48 started at 2024-09-21 16:50:37\n",
            "Epoch 48/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394.4231  Epoch 48 ended at 2024-09-21 16:50:37 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 395.7347 - val_loss: 586.0011\n",
            "Epoch 49 started at 2024-09-21 16:50:37\n",
            "Epoch 49/100\n",
            "\u001b[1m29/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 393.0244  Epoch 49 ended at 2024-09-21 16:50:38 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 394.6535 - val_loss: 583.9417\n",
            "Epoch 50 started at 2024-09-21 16:50:38\n",
            "Epoch 50/100\n",
            "\u001b[1m29/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 391.9358 Epoch 50 ended at 2024-09-21 16:50:38 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 393.4558 - val_loss: 580.9832\n",
            "Epoch 51 started at 2024-09-21 16:50:38\n",
            "Epoch 51/100\n",
            "\u001b[1m28/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390.2458  Epoch 51 ended at 2024-09-21 16:50:38 and took 0.32 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 391.9662 - val_loss: 577.9603\n",
            "Epoch 52 started at 2024-09-21 16:50:38\n",
            "Epoch 52/100\n",
            "\u001b[1m26/49\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389.0979  Epoch 52 ended at 2024-09-21 16:50:38 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 390.7516 - val_loss: 575.7642\n",
            "Epoch 53 started at 2024-09-21 16:50:38\n",
            "Epoch 53/100\n",
            "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 389.3034Epoch 53 ended at 2024-09-21 16:50:39 and took 0.42 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 389.5679 - val_loss: 573.9918\n",
            "Epoch 54 started at 2024-09-21 16:50:39\n",
            "Epoch 54/100\n",
            "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 388.3839Epoch 54 ended at 2024-09-21 16:50:39 and took 0.33 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 388.6422 - val_loss: 571.9931\n",
            "Epoch 55 started at 2024-09-21 16:50:39\n",
            "Epoch 55/100\n",
            "\u001b[1m38/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 387.3156Epoch 55 ended at 2024-09-21 16:50:40 and took 0.54 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 387.7875 - val_loss: 570.8538\n",
            "Epoch 56 started at 2024-09-21 16:50:40\n",
            "Epoch 56/100\n",
            "\u001b[1m35/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 386.4073Epoch 56 ended at 2024-09-21 16:50:40 and took 0.27 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 386.8878 - val_loss: 569.0663\n",
            "Epoch 57 started at 2024-09-21 16:50:40\n",
            "Epoch 57/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 385.9379Epoch 57 ended at 2024-09-21 16:50:40 and took 0.27 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 386.0385 - val_loss: 566.9581\n",
            "Epoch 58 started at 2024-09-21 16:50:40\n",
            "Epoch 58/100\n",
            "\u001b[1m39/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 384.7841Epoch 58 ended at 2024-09-21 16:50:41 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 385.1280 - val_loss: 565.7757\n",
            "Epoch 59 started at 2024-09-21 16:50:41\n",
            "Epoch 59/100\n",
            "\u001b[1m48/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 384.1007Epoch 59 ended at 2024-09-21 16:50:41 and took 0.33 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 384.3059 - val_loss: 564.4121\n",
            "Epoch 60 started at 2024-09-21 16:50:41\n",
            "Epoch 60/100\n",
            "\u001b[1m45/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 383.0468Epoch 60 ended at 2024-09-21 16:50:41 and took 0.37 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 383.3893 - val_loss: 563.5326\n",
            "Epoch 61 started at 2024-09-21 16:50:41\n",
            "Epoch 61/100\n",
            "\u001b[1m35/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 382.2627Epoch 61 ended at 2024-09-21 16:50:42 and took 0.53 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 382.5672 - val_loss: 561.5858\n",
            "Epoch 62 started at 2024-09-21 16:50:42\n",
            "Epoch 62/100\n",
            "\u001b[1m44/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 381.2415Epoch 62 ended at 2024-09-21 16:50:42 and took 0.35 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 381.5392 - val_loss: 560.7573\n",
            "Epoch 63 started at 2024-09-21 16:50:42\n",
            "Epoch 63/100\n",
            "\u001b[1m28/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.5616   Epoch 63 ended at 2024-09-21 16:50:43 and took 0.45 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 380.7716 - val_loss: 559.4930\n",
            "Epoch 64 started at 2024-09-21 16:50:43\n",
            "Epoch 64/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 379.3087 Epoch 64 ended at 2024-09-21 16:50:43 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 379.9615 - val_loss: 558.5945\n",
            "Epoch 65 started at 2024-09-21 16:50:43\n",
            "Epoch 65/100\n",
            "\u001b[1m24/49\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.6631  Epoch 65 ended at 2024-09-21 16:50:43 and took 0.31 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 379.2498 - val_loss: 556.8610\n",
            "Epoch 66 started at 2024-09-21 16:50:43\n",
            "Epoch 66/100\n",
            "\u001b[1m33/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.8243  Epoch 66 ended at 2024-09-21 16:50:43 and took 0.28 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 378.5458 - val_loss: 556.1614\n",
            "Epoch 67 started at 2024-09-21 16:50:43\n",
            "Epoch 67/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377.3528  Epoch 67 ended at 2024-09-21 16:50:44 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 377.9753 - val_loss: 555.1292\n",
            "Epoch 68 started at 2024-09-21 16:50:44\n",
            "Epoch 68/100\n",
            "\u001b[1m30/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.5219 Epoch 68 ended at 2024-09-21 16:50:44 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 377.4365 - val_loss: 554.5688\n",
            "Epoch 69 started at 2024-09-21 16:50:44\n",
            "Epoch 69/100\n",
            "\u001b[1m34/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376.5143 Epoch 69 ended at 2024-09-21 16:50:44 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 376.9204 - val_loss: 554.1722\n",
            "Epoch 70 started at 2024-09-21 16:50:44\n",
            "Epoch 70/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.7686  Epoch 70 ended at 2024-09-21 16:50:44 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 376.3945 - val_loss: 553.2592\n",
            "Epoch 71 started at 2024-09-21 16:50:44\n",
            "Epoch 71/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.1778  Epoch 71 ended at 2024-09-21 16:50:45 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 375.8158 - val_loss: 552.6459\n",
            "Epoch 72 started at 2024-09-21 16:50:45\n",
            "Epoch 72/100\n",
            "\u001b[1m33/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 374.8098  Epoch 72 ended at 2024-09-21 16:50:45 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375.4179 - val_loss: 551.9131\n",
            "Epoch 73 started at 2024-09-21 16:50:45\n",
            "Epoch 73/100\n",
            "\u001b[1m29/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.8861 Epoch 73 ended at 2024-09-21 16:50:45 and took 0.16 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 374.8731 - val_loss: 551.4846\n",
            "Epoch 74 started at 2024-09-21 16:50:45\n",
            "Epoch 74/100\n",
            "\u001b[1m29/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.5483  Epoch 74 ended at 2024-09-21 16:50:45 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 374.4195 - val_loss: 551.3506\n",
            "Epoch 75 started at 2024-09-21 16:50:45\n",
            "Epoch 75/100\n",
            "\u001b[1m28/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.8035  Epoch 75 ended at 2024-09-21 16:50:46 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 373.9807 - val_loss: 550.5983\n",
            "Epoch 76 started at 2024-09-21 16:50:46\n",
            "Epoch 76/100\n",
            "\u001b[1m30/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.8071  Epoch 76 ended at 2024-09-21 16:50:46 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.5676 - val_loss: 551.0144\n",
            "Epoch 77 started at 2024-09-21 16:50:46\n",
            "Epoch 77/100\n",
            "\u001b[1m28/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.8312 Epoch 77 ended at 2024-09-21 16:50:46 and took 0.16 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 373.0520 - val_loss: 550.1033\n",
            "Epoch 78 started at 2024-09-21 16:50:46\n",
            "Epoch 78/100\n",
            "\u001b[1m28/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.4195 Epoch 78 ended at 2024-09-21 16:50:46 and took 0.17 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 372.5487 - val_loss: 550.0017\n",
            "Epoch 79 started at 2024-09-21 16:50:46\n",
            "Epoch 79/100\n",
            "\u001b[1m33/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.6289  Epoch 79 ended at 2024-09-21 16:50:47 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 372.1611 - val_loss: 549.8287\n",
            "Epoch 80 started at 2024-09-21 16:50:47\n",
            "Epoch 80/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371.2697 Epoch 80 ended at 2024-09-21 16:50:47 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 371.7913 - val_loss: 548.9461\n",
            "Epoch 81 started at 2024-09-21 16:50:47\n",
            "Epoch 81/100\n",
            "\u001b[1m45/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 370.9155Epoch 81 ended at 2024-09-21 16:50:47 and took 0.33 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 371.3150 - val_loss: 549.4078\n",
            "Epoch 82 started at 2024-09-21 16:50:47\n",
            "Epoch 82/100\n",
            "\u001b[1m33/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 370.4203 Epoch 82 ended at 2024-09-21 16:50:47 and took 0.17 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 370.9456 - val_loss: 548.4857\n",
            "Epoch 83 started at 2024-09-21 16:50:47\n",
            "Epoch 83/100\n",
            "\u001b[1m33/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.9150 Epoch 83 ended at 2024-09-21 16:50:47 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 370.4831 - val_loss: 548.2629\n",
            "Epoch 84 started at 2024-09-21 16:50:47\n",
            "Epoch 84/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369.3722 Epoch 84 ended at 2024-09-21 16:50:48 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 369.9410 - val_loss: 547.9136\n",
            "Epoch 85 started at 2024-09-21 16:50:48\n",
            "Epoch 85/100\n",
            "\u001b[1m30/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 368.7160  Epoch 85 ended at 2024-09-21 16:50:48 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 369.5287 - val_loss: 547.9305\n",
            "Epoch 86 started at 2024-09-21 16:50:48\n",
            "Epoch 86/100\n",
            "\u001b[1m27/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 367.9328  Epoch 86 ended at 2024-09-21 16:50:48 and took 0.31 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 369.1585 - val_loss: 547.4037\n",
            "Epoch 87 started at 2024-09-21 16:50:48\n",
            "Epoch 87/100\n",
            "\u001b[1m20/49\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 365.9937 Epoch 87 ended at 2024-09-21 16:50:48 and took 0.17 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 368.6050 - val_loss: 547.4439\n",
            "Epoch 88 started at 2024-09-21 16:50:48\n",
            "Epoch 88/100\n",
            "\u001b[1m28/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 367.1464  Epoch 88 ended at 2024-09-21 16:50:49 and took 0.29 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 368.4312 - val_loss: 546.9540\n",
            "Epoch 89 started at 2024-09-21 16:50:49\n",
            "Epoch 89/100\n",
            "\u001b[1m26/49\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.5755  Epoch 89 ended at 2024-09-21 16:50:49 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 367.9551 - val_loss: 547.8690\n",
            "Epoch 90 started at 2024-09-21 16:50:49\n",
            "Epoch 90/100\n",
            "\u001b[1m23/49\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.6427 Epoch 90 ended at 2024-09-21 16:50:49 and took 0.18 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 367.7403 - val_loss: 547.1556\n",
            "Epoch 91 started at 2024-09-21 16:50:49\n",
            "Epoch 91/100\n",
            "\u001b[1m34/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.8070  Epoch 91 ended at 2024-09-21 16:50:49 and took 0.27 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 367.3412 - val_loss: 547.7538\n",
            "Epoch 92 started at 2024-09-21 16:50:49\n",
            "Epoch 92/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.2710 Epoch 92 ended at 2024-09-21 16:50:50 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366.9701 - val_loss: 547.5562\n",
            "Epoch 93 started at 2024-09-21 16:50:50\n",
            "Epoch 93/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.7607 Epoch 93 ended at 2024-09-21 16:50:50 and took 0.15 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 366.5244 - val_loss: 547.4860\n",
            "Epoch 94 started at 2024-09-21 16:50:50\n",
            "Epoch 94/100\n",
            "\u001b[1m45/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.7484Epoch 94 ended at 2024-09-21 16:50:50 and took 0.34 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 366.2153 - val_loss: 547.7843\n",
            "Epoch 95 started at 2024-09-21 16:50:50\n",
            "Epoch 95/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 365.1192  Epoch 95 ended at 2024-09-21 16:50:50 and took 0.28 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 365.9221 - val_loss: 546.9576\n",
            "Epoch 96 started at 2024-09-21 16:50:50\n",
            "Epoch 96/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.7090  Epoch 96 ended at 2024-09-21 16:50:51 and took 0.30 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 365.6263 - val_loss: 547.5847\n",
            "Epoch 97 started at 2024-09-21 16:50:51\n",
            "Epoch 97/100\n",
            "\u001b[1m29/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.0088 Epoch 97 ended at 2024-09-21 16:50:51 and took 0.16 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 365.3505 - val_loss: 547.1466\n",
            "Epoch 98 started at 2024-09-21 16:50:51\n",
            "Epoch 98/100\n",
            "\u001b[1m32/49\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 364.1445 Epoch 98 ended at 2024-09-21 16:50:51 and took 0.16 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 365.0109 - val_loss: 547.0761\n",
            "Epoch 99 started at 2024-09-21 16:50:51\n",
            "Epoch 99/100\n",
            "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363.7246  Epoch 99 ended at 2024-09-21 16:50:51 and took 0.28 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 364.6937 - val_loss: 546.9797\n",
            "Epoch 100 started at 2024-09-21 16:50:51\n",
            "Epoch 100/100\n",
            "\u001b[1m27/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.6340 Epoch 100 ended at 2024-09-21 16:50:51 and took 0.17 seconds\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 364.3600 - val_loss: 547.2324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation on validation set\n",
        "Y_val_pred = test_model.predict(X_val)\n",
        "mse_val = mean_squared_error(Y_val, Y_val_pred)\n",
        "rmse_val = np.sqrt(mse_val)\n",
        "r2_val = r2_score(Y_val, Y_val_pred)\n",
        "\n",
        "# Evaluate on test set\n",
        "Y_test_pred = test_model.predict(X_test)\n",
        "mse_test = mean_squared_error(Y_test, Y_test_pred)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "r2_test = r2_score(Y_test, Y_test_pred)\n",
        "\n",
        "# Output the results\n",
        "{\n",
        "    'Validation MSE': mse_val,\n",
        "    'Validation RMSE': rmse_val,\n",
        "    'Validation R-squared': r2_val,\n",
        "    'Test MSE': mse_test,\n",
        "    'Test RMSE': rmse_test,\n",
        "    'Test R-squared': r2_test\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkUEUJt-Ey-z",
        "outputId": "be96d407-62bb-4821-92ed-b356e73ed897"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Validation MSE': 362.503116350354,\n",
              " 'Validation RMSE': 19.039514603853586,\n",
              " 'Validation R-squared': 0.48855252269089033,\n",
              " 'Test MSE': 385.1344660939575,\n",
              " 'Test RMSE': 19.624843084569047,\n",
              " 'Test R-squared': 0.5077164534340907}"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Assuming `model` is your trained model\n",
        "\n",
        "dnn_weights = test_model.get_weights()\n",
        "\n",
        "# Display weights for each layer\n",
        "for i, layer_weights in enumerate(dnn_weights):\n",
        "    print(f\"Weights of layer {i}:\")\n",
        "    print(layer_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxHkyE7OEzAy",
        "outputId": "02f9da02-0124-4f69-9055-172500f92e8d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights of layer 0:\n",
            "[[-0.00385573 -0.05515384  0.3191799  -0.11393119  0.05338969 -0.03676246\n",
            "   0.0186104   0.45700106  0.07281897 -0.03011778  0.26674896  0.03673965\n",
            "   0.05050101  0.01797141 -0.08175103  0.03709345 -0.03161908  0.45877194\n",
            "  -0.1987065  -0.20256376  0.2924498   0.12093332  0.22305241  0.43308768\n",
            "   0.00798097  0.4722086  -0.08382563 -0.04708357 -0.0995295   0.2253246 ]\n",
            " [ 0.36439928 -0.02049484 -0.370918    0.0251051  -0.44439438  0.1464737\n",
            "   0.2501921   0.13649005  0.32543635  0.20248006  0.0600948  -0.46689448\n",
            "   0.13686296  0.05366354  0.0227036  -0.24903503  0.2589822   0.22576919\n",
            "  -0.4794699   0.09905642  0.18330945  0.20112158 -0.15712701  0.5032695\n",
            "  -0.10956576  0.33978534  0.06447751 -0.30660376 -0.3669562   0.19377914]\n",
            " [-0.10642929  0.16490076  0.3375029   0.42796132 -0.25210428  0.06723152\n",
            "   0.05112491 -0.12539527  0.31637976  0.24447607 -0.04945817  0.24902871\n",
            "   0.03780613 -0.07357731 -0.0856346  -0.10824379 -0.3375201  -0.02594751\n",
            "   0.19921565  0.11225715 -0.11611332 -0.0845684   0.2064935  -0.10411967\n",
            "  -0.11813331 -0.01269619  0.00496338 -0.17152895  0.15228987  0.16452594]\n",
            " [-0.3194039  -0.13028835  0.15852734 -0.3176404   0.14718421  0.07698563\n",
            "   0.12566264  0.0739895   0.22722985  0.05517614  0.18576677 -0.18950881\n",
            "  -0.12397589  0.35809404  0.452461    0.04713022  0.37183827 -0.05832814\n",
            "  -0.21311201  0.01965633  0.19365485  0.26263958  0.06066024  0.13096003\n",
            "   0.1976908   0.1985753  -0.1627959  -0.04007065 -0.14006022  0.12529261]\n",
            " [-0.26821858  0.08258865  0.1861631  -0.16833961  0.06968087  0.2493105\n",
            "  -0.14117704  0.01672181  0.10779508 -0.10792367  0.04824356 -0.03520446\n",
            "   0.1978123  -0.10583897 -0.15141785  0.03479932 -0.04754201  0.0504959\n",
            "  -0.45225474  0.54119325 -0.18378033 -0.33498773 -0.09261227 -0.46657386\n",
            "  -0.04411772 -0.26171184  0.24956383  0.25337565  0.26403219 -0.17405757]\n",
            " [ 0.13142306  0.32856706  0.3318358  -0.17067122 -0.22012886 -0.31278852\n",
            "  -0.2655128  -0.01866246  0.14638269 -0.36664364 -0.18438382  0.00859427\n",
            "  -0.16366044  0.09696036  0.45255622  0.44032508 -0.13158831 -0.19257383\n",
            "   0.14431971 -0.14591084  0.22600323 -0.03082312 -0.0505953   0.70045453\n",
            "   0.31620494 -0.16015063 -0.13235146  0.43221438  0.26166373 -0.2810642 ]\n",
            " [-0.04087224 -0.07395055  0.12578559  0.41384992 -0.45509002 -0.14036033\n",
            "   0.34223384  0.28982005  0.14110522  0.22789961 -0.19135207  0.2608151\n",
            "   0.21590336  0.21138087 -0.02783327 -0.09597152  0.16041265  0.03013401\n",
            "  -0.11495034 -0.38589534 -0.06192464  0.17923765 -0.15094288 -0.22683255\n",
            "   0.06733438  0.04394784 -0.1698983  -0.0334133  -0.38281563 -0.18373607]]\n",
            "Weights of layer 1:\n",
            "[0.9671921  0.9972322  0.85344404 0.96713334 0.75992    0.85243624\n",
            " 0.9680112  0.77061003 0.7829031  0.9095786  1.033571   0.74354213\n",
            " 0.88345665 0.8308059  0.85209805 0.7503549  0.86887985 0.96062475\n",
            " 0.676233   0.8538336  0.93115026 0.8948896  0.82176316 0.8665018\n",
            " 0.7604883  0.9191325  0.77379954 0.7007195  1.0215931  0.78840464]\n",
            "Weights of layer 2:\n",
            "[[-1.65455028e-01  2.47624606e-01  2.93869227e-01  5.89541614e-01\n",
            "   5.84383309e-01  4.26597327e-01 -1.74529746e-01 -4.34332006e-02\n",
            "   1.04406789e-01  2.00820893e-01  6.92498028e-01  1.17438018e-01\n",
            "  -1.99728847e-01 -7.49981344e-01 -2.66064048e-01  7.65474677e-01]\n",
            " [-3.48797888e-01  6.47030890e-01  2.81924516e-01  7.83669770e-01\n",
            "   3.71619672e-01  6.84701622e-01 -1.65179223e-01 -2.49962136e-01\n",
            "   2.38432407e-01  3.94894660e-01  3.42715204e-01  5.88307559e-01\n",
            "  -3.10116291e-01  3.39839101e-01 -7.34539777e-02  7.75483370e-01]\n",
            " [ 1.40950739e-01 -1.80657461e-01  3.29885930e-01  3.20218593e-01\n",
            "   4.64042455e-01 -1.39769807e-01 -2.60767877e-01 -1.27977937e-01\n",
            "  -1.85001612e-01  2.14216067e-03  4.83512968e-01 -5.58299683e-02\n",
            "  -1.16315000e-01  3.51219654e-01  1.79914549e-01 -9.88354161e-02]\n",
            " [-3.58895987e-01  1.73384979e-01  7.02044070e-01  5.50282180e-01\n",
            "   6.00271583e-01  5.76628208e-01  5.68041625e-03 -2.58029193e-01\n",
            "   4.33843464e-01  1.72966897e-01  4.37442690e-01  2.83266842e-01\n",
            "  -3.29423726e-01 -6.60687685e-01 -1.64929718e-01  3.18233401e-01]\n",
            " [-3.91537070e-01  1.82118028e-01  4.23404068e-01  4.69950199e-01\n",
            "   2.08274603e-01  3.54040325e-01  1.67912781e-01 -1.75395325e-01\n",
            "  -3.94467860e-01  2.53342420e-01  3.49143952e-01  2.49416038e-01\n",
            "   3.45671512e-02  1.18065250e+00  9.88104101e-03 -2.99555007e-02]\n",
            " [-1.89677730e-01  4.59927201e-01  8.62717092e-01  4.75678951e-01\n",
            "   7.01655567e-01 -3.22317965e-02 -3.64760607e-01  3.52585346e-01\n",
            "   4.89714950e-01  6.48872733e-01  4.94769096e-01  5.67919433e-01\n",
            "  -2.61974275e-01 -1.18562743e-01  3.40766847e-01  7.11633682e-01]\n",
            " [-5.67666218e-02  6.79790080e-01  2.00165316e-01  5.71639061e-01\n",
            "   4.89535898e-01 -3.97658169e-01  9.38936770e-02 -2.77604043e-01\n",
            "   2.29288429e-01  2.94780433e-01  2.69454360e-01  6.28721952e-01\n",
            "  -6.10690471e-03  1.55969545e-01 -1.65569812e-01  4.36754793e-01]\n",
            " [ 1.08645558e-01  2.48518914e-01  4.92326736e-01  3.71850997e-01\n",
            "   1.58258498e-01 -7.44075954e-01  6.00807555e-03  3.73487592e-01\n",
            "  -6.29976541e-02  2.53546506e-01  1.64052278e-01  1.31235674e-01\n",
            "  -8.43656808e-02  5.75380325e-01  5.15643284e-02  7.58577734e-02]\n",
            " [-2.29434222e-01  2.40234137e-01  3.95814240e-01  5.27619183e-01\n",
            "   1.71222761e-01  7.08901644e-01 -2.22229868e-01  4.58599953e-03\n",
            "  -2.97452539e-01  1.09744281e-01  5.65333903e-01  2.63353735e-01\n",
            "   2.30702534e-01  3.15177292e-01 -8.37724060e-02  2.15083867e-01]\n",
            " [-4.71529141e-02  1.24600399e-02  7.38325596e-01  6.07570648e-01\n",
            "   2.30077848e-01  5.18488288e-02  1.88125353e-02 -2.28584111e-01\n",
            "  -5.93060255e-02  3.21563005e-01  1.17576540e-01  1.07754320e-01\n",
            "   2.74887174e-01  3.64006869e-02  8.10144246e-02  2.47181386e-01]\n",
            " [-2.85245985e-01  2.84177035e-01  3.53997707e-01  4.70393568e-01\n",
            "   3.89498770e-01 -1.28319418e+00 -6.47856444e-02 -1.20124230e-02\n",
            "   4.81301069e-01  6.08409584e-01  3.08148563e-01  2.69688129e-01\n",
            "   2.74942815e-01  8.41485262e-02 -3.59356970e-01  2.96589524e-01]\n",
            " [-3.58286411e-01  6.15004182e-01  5.93632698e-01  1.17149442e-01\n",
            "   2.85103172e-01 -1.82099640e-01  2.08864331e-01 -2.41332904e-01\n",
            "   6.26783013e-01 -5.06298430e-02  7.55450606e-01  9.18667093e-02\n",
            "   1.29726693e-01 -8.21687341e-01  8.07752274e-03  2.20904499e-01]\n",
            " [ 1.74488157e-01  3.15366760e-02  8.29010487e-01  8.05608809e-01\n",
            "   4.64887887e-01 -6.52990714e-02 -2.29874462e-01  6.86779395e-02\n",
            "   1.87328622e-01  2.01091647e-01  4.99128193e-01  1.82935089e-01\n",
            "  -3.37841392e-01  3.82791102e-01  1.45134509e-01  3.21686625e-01]\n",
            " [-3.76063958e-02  1.13731503e-01  4.83915329e-01  4.55799669e-01\n",
            "   2.76237547e-01 -2.67824270e-02  1.47356153e-01  2.97753215e-01\n",
            "  -8.63065422e-02 -9.31009650e-02  5.29987574e-01  1.74984723e-01\n",
            "  -8.06293637e-02  6.71570241e-01 -2.37167835e-01  6.35787189e-01]\n",
            " [-2.19309866e-01  5.84347069e-01  6.94757342e-01  6.74409151e-01\n",
            "   6.97466671e-01  7.52332760e-03  8.39412287e-02  1.53753430e-01\n",
            "   1.09770916e-01  5.80247343e-01  2.32534617e-01  3.14364493e-01\n",
            "  -3.95801783e-01  3.70981574e-01 -2.56438255e-01  6.01294935e-01]\n",
            " [ 1.39774993e-01  5.72017372e-01  5.76715350e-01  2.47426167e-01\n",
            "   3.32999170e-01 -5.51956370e-02  9.91245657e-02 -3.38987678e-01\n",
            "   4.39715326e-01  1.97091296e-01  2.76253700e-01  4.62779969e-01\n",
            "  -2.73829043e-01 -3.24082673e-01  1.99232489e-01  6.84045374e-01]\n",
            " [ 2.59172529e-01  3.61443222e-01  9.75221917e-02  5.24357677e-01\n",
            "   5.01914918e-01 -5.98760009e-01 -3.02248687e-01 -1.52920738e-01\n",
            "   3.69660616e-01  3.92859548e-01  4.40880120e-01  4.90954459e-01\n",
            "   1.45796016e-02  1.00006789e-01 -5.69229312e-02  7.41105139e-01]\n",
            " [-1.60548732e-01  2.39708662e-01  5.15338540e-01  5.29524982e-01\n",
            "   5.37547529e-01 -4.18880224e-01 -1.86033562e-01 -1.14197284e-01\n",
            "   1.12126432e-01  4.10349935e-01  5.18036485e-01  6.01818800e-01\n",
            "  -1.21618003e-01  3.12893271e-01 -1.87090889e-01  3.62828195e-01]\n",
            " [ 1.53052598e-01  5.54515123e-01  4.93252367e-01  9.65709165e-02\n",
            "   3.52244169e-01  4.46045905e-01 -3.03035736e-01 -2.17699304e-01\n",
            "   1.81701005e-01 -8.84135291e-02 -1.72179714e-02  1.60061732e-01\n",
            "   2.01125592e-01 -4.88336176e-01 -1.27671508e-03  3.79914671e-01]\n",
            " [-2.07247391e-01  6.76576495e-01  6.33838713e-01  4.32714969e-01\n",
            "   5.09489179e-01  4.50545967e-01 -4.66538826e-03 -3.04507673e-01\n",
            "   8.63893516e-03 -3.15449089e-02  4.63841975e-01  5.72014153e-01\n",
            "  -3.92002225e-01  6.91788942e-02 -1.50586352e-01  6.17711782e-01]\n",
            " [-1.69463798e-01  1.09881833e-01  4.53917086e-01  2.96992660e-01\n",
            "   5.66083848e-01 -9.85666215e-02  2.09938854e-01 -2.28622973e-01\n",
            "   1.41637295e-01  8.73334408e-02  4.54609543e-01  4.96272057e-01\n",
            "   1.54818267e-01  6.08752787e-01 -1.38257697e-01  4.80558127e-01]\n",
            " [-2.91547906e-02  6.81215405e-01  2.07235619e-01  2.52258062e-01\n",
            "   1.99222013e-01 -6.25625372e-01  1.60113230e-01  2.91233420e-01\n",
            "   4.29394603e-01  4.25241113e-01  6.64800167e-01  4.64161426e-01\n",
            "  -2.46630773e-01 -6.92516984e-03  5.65224653e-03  5.51653743e-01]\n",
            " [ 2.45687410e-01  5.55595160e-01  5.13093650e-01  1.20172836e-01\n",
            "   2.97646344e-01 -4.74117458e-01  1.09676212e-01 -1.16504349e-01\n",
            "   3.96476120e-01  5.08969128e-01  3.67761642e-01  4.15310383e-01\n",
            "  -3.19247961e-01 -4.20288831e-01 -3.66118163e-01  4.99088407e-01]\n",
            " [-1.94801643e-01  2.51175165e-01 -2.74379943e-02  4.40128446e-01\n",
            "   5.07035136e-01  6.82447195e-01 -3.04509670e-01 -1.79436147e-01\n",
            "  -1.35324776e-01 -8.03669989e-02  6.13634288e-01  1.98693082e-01\n",
            "   1.63854167e-01  5.68137288e-01  8.51369798e-02  3.04523319e-01]\n",
            " [ 8.37076176e-03  4.89539236e-01  4.45158899e-01  3.53481919e-01\n",
            "   2.14137688e-01 -7.56624639e-01  9.01065692e-02 -1.03236169e-01\n",
            "   3.99792761e-01  5.95135570e-01  3.77193689e-01  2.76537001e-01\n",
            "  -2.19298676e-01  4.48065437e-02 -1.44465849e-01  3.75646949e-01]\n",
            " [ 1.55238032e-01  1.49756104e-01  5.94014168e-01  4.18965936e-01\n",
            "   5.50948143e-01 -6.86135173e-01 -3.54725540e-01 -1.96417928e-01\n",
            "   2.58546993e-02  9.34137553e-02  5.56877971e-01  3.82656276e-01\n",
            "   3.09806373e-02  4.51062210e-02  1.75122485e-01  5.67473114e-01]\n",
            " [-1.23691835e-01  3.06799322e-01  6.64176643e-01  1.51282519e-01\n",
            "   3.98789406e-01  1.89667866e-01 -3.36757064e-01  8.77433866e-02\n",
            "   2.70586014e-01  4.31137353e-01  3.96719247e-01  7.20792562e-02\n",
            "  -1.03152215e-01 -5.11860609e-01 -1.08259013e-02  6.92974264e-03]\n",
            " [-3.47938597e-01  4.11895484e-01  2.64703393e-01  2.91658431e-01\n",
            "   3.86257201e-01  4.95038144e-02 -1.88607588e-01 -2.11413093e-02\n",
            "   7.77597010e-01  7.43005097e-01  6.49837077e-01  4.66316193e-01\n",
            "   1.70060739e-01 -1.84977815e-01 -2.51980305e-01  7.36762345e-01]\n",
            " [ 2.56623864e-01  2.54960924e-01  3.25053602e-01  6.56051815e-01\n",
            "   1.05654210e-01  1.69685155e-01 -2.65270263e-01 -1.94569245e-01\n",
            "   2.73938417e-01  4.03094381e-01  1.12919532e-01  3.15586120e-01\n",
            "  -3.87312502e-01  4.73210454e-01 -6.86585680e-02  3.82999867e-01]\n",
            " [ 3.12620759e-01  6.59756362e-01  3.92611444e-01  1.62978485e-01\n",
            "   2.47023225e-01 -1.06273443e-01 -1.94136705e-02 -1.30159616e-01\n",
            "   6.10041559e-01  2.52337843e-01  8.71588513e-02  8.24452519e-01\n",
            "  -3.78617853e-01  1.33618802e-01  5.86649552e-02  3.96396190e-01]]\n",
            "Weights of layer 3:\n",
            "[-0.03987243  0.61903644  0.60876614  0.56704634  0.5970816  -0.22050321\n",
            " -0.05491115  0.01443784  0.6194114   0.55261606  0.5686528   0.5918525\n",
            " -0.0756335  -0.4631714  -0.04283144  0.68273187]\n",
            "Weights of layer 4:\n",
            "[[ 1.60533950e-01 -3.76847506e-01  4.14553523e-01  4.57123905e-01\n",
            "   1.49688452e-01 -1.49096921e-01  2.92946100e-01 -4.58509326e-01]\n",
            " [ 2.21439347e-01  5.08937180e-01  5.46679311e-02  2.23135874e-02\n",
            "   3.14145029e-01  8.64581227e-01 -7.94916749e-02  1.00271543e-03]\n",
            " [ 7.13390827e-01  7.21553445e-01 -4.27431986e-02  8.40900004e-01\n",
            "   4.15690206e-02  1.91371053e-01 -4.47878391e-02  7.41088033e-01]\n",
            " [ 3.47501218e-01  7.13135242e-01 -4.17495146e-02  6.68713331e-01\n",
            "  -1.37851655e-01  7.70127296e-01 -5.10306716e-01  5.01714587e-01]\n",
            " [ 3.92364264e-01  6.59540117e-01 -1.11885034e-01  3.66947025e-01\n",
            "   6.12970889e-02  6.76949918e-01 -6.74576610e-02  5.97446978e-01]\n",
            " [-1.21669960e+00 -1.41410387e+00  3.87424558e-01 -7.68636346e-01\n",
            "   9.69618857e-01 -1.38907540e+00  2.28724331e-01 -1.30147111e+00]\n",
            " [-2.22715527e-01 -4.00113583e-01  2.00784370e-01 -4.39108759e-01\n",
            "   1.93350449e-01  9.60816890e-02  1.49857670e-01  1.35507733e-01]\n",
            " [-1.96138680e-01  3.05943221e-01  3.54238510e-01 -6.76394105e-02\n",
            "  -4.35843796e-01 -3.32573831e-01  2.41104901e-01  3.95921499e-01]\n",
            " [ 5.00969172e-01  3.86708975e-01 -4.42151092e-02  8.31925750e-01\n",
            "   2.43956566e-01  4.85454768e-01  4.11359966e-01  9.00011957e-01]\n",
            " [ 2.84631580e-01  2.33973444e-01  2.01251671e-01  4.97209504e-02\n",
            "  -2.35607922e-02  7.23541796e-01  4.18978691e-01  3.34647417e-01]\n",
            " [ 5.25582373e-01  1.22534484e-01  8.14296156e-02  7.51173973e-01\n",
            "  -1.89877525e-01  6.80508852e-01  8.44361261e-02  2.52987802e-01]\n",
            " [ 1.10061996e-01  7.16240048e-01  3.75088632e-01  5.31549633e-01\n",
            "   1.51827112e-01  5.37210047e-01  1.28550185e-02  5.83809674e-01]\n",
            " [ 3.12589198e-01 -1.11233927e-01  1.06281996e-01 -3.43021989e-01\n",
            "   4.01891351e-01 -6.08343296e-02  4.71120715e-01  8.87537077e-02]\n",
            " [-5.32158971e-01 -8.30063999e-01  8.00094187e-01 -1.07846284e+00\n",
            "   3.39985907e-01 -6.26409948e-01  1.52688488e-01 -1.13411140e+00]\n",
            " [-2.61051178e-01  1.83000602e-02 -4.87957984e-01  4.96983193e-02\n",
            "  -4.78350222e-01 -3.42826486e-01  8.08045361e-03 -4.00974602e-01]\n",
            " [ 5.78587472e-01  4.66119766e-01 -3.72640967e-01  2.15867504e-01\n",
            "  -3.26184303e-01  5.93626559e-01 -4.21031773e-01  1.81500316e-01]]\n",
            "Weights of layer 5:\n",
            "[ 0.41878393  0.4515126  -0.1873469   0.47127247 -0.2941163   0.44583797\n",
            " -0.03984545  0.49508524]\n",
            "Weights of layer 6:\n",
            "[[-0.22643311  0.29276004  0.39094624 -0.16707788]\n",
            " [ 0.16026327 -0.7124879   0.86088324 -0.26400292]\n",
            " [ 0.5437434  -0.58663565 -0.8296683  -0.10027113]\n",
            " [-0.45918152 -0.31096932  0.6876076   0.45034152]\n",
            " [-0.47534764 -0.09694599 -1.2467186  -0.23924498]\n",
            " [-0.61162496  0.20527714  1.1864123   0.13266966]\n",
            " [-0.5495956   0.25485206 -0.5093362   0.0301492 ]\n",
            " [ 0.12093011  0.549085    0.67768645 -0.74361545]]\n",
            "Weights of layer 7:\n",
            "[-0.00822643 -0.03658712  0.3843223  -0.0432947 ]\n",
            "Weights of layer 8:\n",
            "[[-0.09577772]\n",
            " [-0.6511765 ]\n",
            " [ 1.0543765 ]\n",
            " [-0.60556704]]\n",
            "Weights of layer 9:\n",
            "[0.3072138]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T6JNfg6XEzET"
      },
      "execution_count": 130,
      "outputs": []
    }
  ]
}